import streamlit as st
from streamlit_mic_recorder import mic_recorder
from groq import Groq
from state import app  # рдЖрдкрдХреЗ LangGraph рдПрдЬреЗрдВрдЯ рдХрд╛ рд▓реЙрдЬрд┐рдХ
import io
import base64
from gtts import gTTS

# --- 1. рд╕реЗрд╢рди рд╕реНрдЯреЗрдЯ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬреЗрд╢рди (рд╕рдмрд╕реЗ рдКрдкрд░) ---
# рдпрд╣ рдПрд░рд░ рд░реЛрдХрдиреЗ рдФрд░ рдлреАрдбрдмреИрдХ рд▓реВрдк рдХреЛ рдирд┐рдпрдВрддреНрд░рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЕрдирд┐рд╡рд╛рд░реНрдп рд╣реИ
if "is_processing" not in st.session_state:
    st.session_state.is_processing = False

if "last_played_idx" not in st.session_state:
    st.session_state.last_played_idx = -1 

if "chat_history" not in st.session_state:
    # рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рдХрд╛ рдкрд╣рд▓рд╛ рдЧреНрд░реАрдЯрд┐рдВрдЧ (Assistant speaks first)
    greeting = "рдирдорд╕реНрддреЗ! рдореИрдВ рдЖрдкрдХрд╛ рд╕рд░рдХрд╛рд░реА рдпреЛрдЬрдирд╛ рд╕рд╣рд╛рдпрдХ рд╣реВрдБред рдЕрдкрдиреА рдкрд╛рддреНрд░рддрд╛ рдЬрд╛рдирдиреЗ рдХреЗ рд▓рд┐рдП рдХреГрдкрдпрд╛ рдЕрдкрдиреА рдЖрдпреБ рдФрд░ рдЖрдп рдмрддрд╛рдПрдВред"
    st.session_state.chat_history = [{"role": "assistant", "text": greeting}]

if "thread_id" not in st.session_state:
    st.session_state.thread_id = "hi_session_" + str(hash("agentic_hindi"))

# --- 2. UI рдХреЙрдиреНрдлрд╝рд┐рдЧрд░реЗрд╢рди рдФрд░ рд╕реНрдЯрд╛рдЗрд▓рд┐рдВрдЧ ---
st.set_page_config(page_title="рд╕рд░рдХрд╛рд░реА рдпреЛрдЬрдирд╛ рд╕рд╣рд╛рдпрдХ", layout="centered")

st.markdown("""
    <style>
    .stApp { background: transparent !important; }
    .stApp::before {
        content: ""; position: fixed; top: 0; left: 0; width: 100vw; height: 100vh;
        background-image: url("https://www.hindustantimes.com/ht-img/img/2024/02/16/1600x900/Cloud-text-of--India--written-in-56-Languages--Int_1708105329979.jpg");
        background-size: cover; filter: blur(10px) brightness(0.15); z-index: -1;
    }
    .chat-container { display: flex; flex-direction: column; gap: 10px; padding: 10px; }
    .bubble { padding: 15px; border-radius: 15px; max-width: 85%; color: white; margin-bottom: 5px; }
    .assistant { background: rgba(255, 75, 75, 0.25); align-self: flex-start; border-left: 5px solid #ff4b4b; }
    .user { background: rgba(255, 255, 255, 0.15); align-self: flex-end; border-right: 5px solid #ddd; text-align: right; }
    .stButton>button { border-radius: 50%; width: 40px; height: 40px; padding: 0; }
    </style>
""", unsafe_allow_html=True)

# Groq рдХреНрд▓рд╛рдЗрдВрдЯ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬреЗрд╢рди
client = Groq(api_key=st.secrets["GROQ_API_KEY"])

# --- 3. рд╣реЗрд▓реНрдкрд░ рдлрдВрдХреНрд╢рдиреНрд╕ ---
def text_to_speech_b64(text):
    """рдЯреЗрдХреНрд╕реНрдЯ рдХреЛ рдСрдбрд┐рдпреЛ (Base64) рдореЗрдВ рдмрджрд▓рддрд╛ рд╣реИ"""
    try:
        tts = gTTS(text=text, lang='hi')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return base64.b64encode(fp.getvalue()).decode()
    except Exception:
        return ""

# --- 4. рдореБрдЦреНрдп рдЗрдВрдЯрд░рдлреЗрд╕ ---
st.title("рд╕рд░рдХрд╛рд░реА рдпреЛрдЬрдирд╛ рд╕рд╣рд╛рдпрдХ ЁЯПЫя╕П")
st.write("рдЕрдкрдиреА рдЬрд╛рдирдХрд╛рд░реА рд╕рд╛рдЭрд╛ рдХрд░реЗрдВ рдФрд░ рдкрд╛рддреНрд░ рдпреЛрдЬрдирд╛рдПрдВ рдЦреЛрдЬреЗрдВред")

# рдХреЗрд╡рд▓ рдирдП рдЕрд╕рд┐рд╕реНрдЯреЗрдВрдЯ рдореИрд╕реЗрдЬ рдХреЛ рдСрдЯреЛрдкреНрд▓реЗ рдХрд░реЗрдВ (Feedback loop protection)
current_last_idx = len(st.session_state.chat_history) - 1
if st.session_state.chat_history[-1]["role"] == "assistant" and st.session_state.last_played_idx < current_last_idx:
    audio_b64 = text_to_speech_b64(st.session_state.chat_history[-1]["text"])
    if audio_b64:
        st.markdown(f'<audio autoplay src="data:audio/mp3;base64,{audio_b64}"></audio>', unsafe_allow_html=True)
        st.session_state.last_played_idx = current_last_idx

# рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рдкреНрд░рджрд░реНрд╢рд┐рдд рдХрд░реЗрдВ (Subtitles style)
st.markdown('<div class="chat-container">', unsafe_allow_html=True)
for i, chat in enumerate(st.session_state.chat_history):
    role_class = "assistant" if chat["role"] == "assistant" else "user"
    col1, col2 = st.columns([0.88, 0.12]) if chat["role"] == "assistant" else st.columns([0.12, 0.88])
    
    with (col1 if chat["role"] == "assistant" else col2):
        st.markdown(f'<div class="bubble {role_class}"><b>{"рд╕рд╣рд╛рдпрдХ" if chat["role"] == "assistant" else "рдЖрдк"}:</b><br>{chat["text"]}</div>', unsafe_allow_html=True)
    
    if chat["role"] == "assistant":
        with col2:
            if st.button("ЁЯФК", key=f"btn_{i}"): # Replay icon
                b64 = text_to_speech_b64(chat["text"])
                st.markdown(f'<audio autoplay src="data:audio/mp3;base64,{b64}"></audio>', unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

st.write("---")

# --- 5. рд╕реБрд░рдХреНрд╖рд┐рдд рд╡реЙрдЗрд╕ рдЗрдирдкреБрдЯ (Voice-first interaction) ---
if not st.session_state.is_processing:
    st.subheader("рдЕрдкрдиреА рдЖрд╡рд╛рдЬ рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рджреЗрдВ:")
    # 'key' рдХреЛ рдЧрддрд┐рд╢реАрд▓ рдмрдирд╛рдпрд╛ рдЧрдпрд╛ рд╣реИ рддрд╛рдХрд┐ рдкреБрд░рд╛рдиреЗ рдЗрдирдкреБрдЯ рд░рд┐рдкреАрдЯ рди рд╣реЛрдВ
    audio_input = mic_recorder(
        start_prompt="рдмреЛрд▓рдирд╛ рд╢реБрд░реВ рдХрд░реЗрдВ ЁЯОд", 
        stop_prompt="рд░реЛрдХреЗрдВ ЁЯЫС", 
        key=f"rec_{len(st.session_state.chat_history)}" 
    )
else:
    st.info("тМЫ рд╕рд╣рд╛рдпрдХ рд╡рд┐рдЪрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реИ... рдХреГрдкрдпрд╛ рдкреНрд░рддреАрдХреНрд╖рд╛ рдХрд░реЗрдВред")
    audio_input = None

if audio_input:
    st.session_state.is_processing = True
    
    with st.spinner("рдкрд╣рдЪрд╛рдирд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ..."):
        # A. STT (Hindi Whisper)
        transcription = client.audio.transcriptions.create(
            file=("input.wav", audio_input['bytes']),
            model="whisper-large-v3", 
            language="hi"
        )
        user_text = transcription.text
        st.session_state.chat_history.append({"role": "user", "text": user_text})

        # B. рдПрдЬреЗрдВрдЯ рд░реАрдЬрдирд┐рдВрдЧ (LangGraph Planner-Executor-Evaluator loop)
        config = {"configurable": {"thread_id": st.session_state.thread_id}, "recursion_limit": 15}
        try:
            # рдПрдЬреЗрдВрдЯ рдЦреБрдж рддрдп рдХрд░реЗрдЧрд╛ рдХрд┐ рдЬрд╛рдирдХрд╛рд░реА рдкреВрд░реА рд╣реИ рдпрд╛ рдирд╣реАрдВ (Failure Handling)
            result = app.invoke({"messages": [user_text]}, config=config)
            assistant_reply = result["messages"][-1]
            st.session_state.chat_history.append({"role": "assistant", "text": assistant_reply})
        except Exception as e:
            st.error(f"рддреНрд░реБрдЯрд┐: {e}")
            
    st.session_state.is_processing = False
    st.rerun()